# PSA Card Grading Model

AI-powered PSA card grading prediction system using ensemble learning with adaptive features.

## Model Performance (5-Fold Cross-Validation)

**Balanced Ensemble Results** (10,288 images):

| Metric | Performance |
|--------|-------------|
| **Exact Match** | **53.4%** (SD: 1.1%) |
| **Within 1 Grade** | **73.5%** |
| **Within 2 Grades** | **84.9%** |

### Per-Grade Exact Match Accuracy

| Grade | Accuracy | Correct/Total | vs Baseline | Notes |
|-------|----------|---------------|-------------|-------|
| PSA 1 | 68.7% | 575/837 | -1.9% | Strong - distinctive damage |
| PSA 2 | **46.3%** | 302/652 | **+11.8%** | Improved with specialist |
| PSA 3 | 63.8% | 720/1129 | -5.6% | Good |
| PSA 4 | 67.0% | 647/966 | -7.4% | Strong |
| PSA 5 | **45.2%** | 283/626 | **+18.2%** | Major improvement |
| PSA 6 | 50.6% | 722/1428 | -6.3% | Moderate |
| PSA 7 | 44.7% | 610/1365 | -2.4% | Moderate |
| PSA 8 | **43.5%** | 439/1009 | **+14.8%** | Major improvement |
| PSA 9 | 42.8% | 513/1199 | -7.4% | Confused with 8, 10 |
| PSA 10 | 63.2% | 681/1077 | -2.1% | Strong |

### Hard Class Improvements

The balanced ensemble specifically targets PSA 2, 5, and 8 which were previously the worst performers:

| Grade | Baseline | Improved | Change |
|-------|----------|----------|--------|
| PSA 2 | 34.5% | **46.3%** | **+11.8%** |
| PSA 5 | 27.0% | **45.2%** | **+18.2%** |
| PSA 8 | 28.7% | **43.5%** | **+14.8%** |

### Model Components

| Component | Status | Purpose |
|-----------|--------|---------|
| Base Model | âœ… Active | 500 trees, good overall accuracy |
| Specialist Model | âœ… Active | Upweighted hard classes (2, 5, 8) |
| SMOTE Oversampling | âœ… Active | 1.5x synthetic samples for hard classes |
| Confidence Blending | âœ… Active | Combines base + specialist predictions |
| Advanced Features (v4) | âœ… Active | HOG, LBP, corners, centering |

## Quick Start

### Step 1: Create Data Manifest (Prevents Leakage)

```bash
python scripts/data_management/create_data_manifest.py \
    --data-dir data/training \
    --output data/data_manifest.csv \
    --create-splits
```

This creates:
- `data_manifest.csv` - Full manifest with duplicate flags
- `data_manifest_clean.csv` - Deduplicated images only
- `data_manifest_splits.csv` - Grouped CV folds

### Step 2: Extract Features

```bash
# Advanced features (Adaptive ROI + Art-Box Centering)
python scripts/feature_extraction/extract_advanced_features.py

# CNN features (MobileNetV2 embeddings, 1,280 dims)
python scripts/feature_extraction/extract_cnn_features_batch.py
```

### Step 3: Train Models

**Option A: Ensemble Model (Recommended for best accuracy)**
```bash
Rscript training/train_ensemble_model.R
```

**Option B: Single Tiered Model (Faster)**
```bash
Rscript training/train_tiered_model.R
```

### Step 4: Make Predictions

```r
# Ensemble prediction (highest accuracy)
source("Prediction_New/predict_ensemble.R")
result <- predict_grade_ensemble("path/to/card.jpg", use_tta = TRUE)
print_ensemble_prediction(result)

# Single model prediction (faster)
source("Prediction_New/predict_new.R")
result <- predict_grade("path/to/card.jpg")
```

## Model Architecture

### Ensemble Model (`train_ensemble_model.R`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT IMAGE                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                â”‚                â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Model 1 â”‚     â”‚ Model 2 â”‚ ... â”‚ Model 5 â”‚  (Diverse configs)
    â”‚seed=42  â”‚     â”‚seed=123 â”‚     â”‚seed=999 â”‚
    â”‚feat=365 â”‚     â”‚feat=300 â”‚     â”‚feat=350 â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                â”‚                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ Average probabilities
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Confusion-Pair Check  â”‚  (If borderline 30-70%)
              â”‚ 6â†”7, 7â†”8, 8â†”9, 9â†”10  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Temperature Scaling   â”‚  (Per-tier calibration)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Ordinal Post-Process  â”‚  (Prefer adjacent grades)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚  OUTPUT   â”‚
                    â”‚ PSA Grade â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component | Purpose | Expected Impact |
|-----------|---------|-----------------|
| 5-Model Ensemble | Reduce variance, diverse views | +2-3% |
| Confusion-Pair Specialists | Better boundary decisions | +1-2% |
| Ordinal Loss | Prefer adjacent errors | +0.5-1% |
| Temperature Calibration | Better probability estimates | +0.5-1% |
| TTA (Test-Time Aug) | Reduce scan variance | +1-2% |
| Leakage-Free CV | Accurate metrics | True measurement |

## Feature Engineering

### Advanced Features (v4) - 6,400+ dimensions

| Category | Features | Description |
|----------|----------|-------------|
| HOG | ~6,100 | Edge/corner shape patterns |
| LBP | 26 | Surface texture analysis |
| Art-Box Centering | 11 | Pixel-perfect 55/45 ratio |
| Adaptive Corners | 36 | Contour-based corner crops + whitening |
| Corner Sharpness | 35 | Gradient magnitude per corner |
| LoG Kurtosis | 4 | Scratch/glare detection |
| High-res Corner | 80 | Original-resolution analysis |
| LAB Center | 2 | Perceptual lightness |

### CNN Features - 1,280 dimensions

MobileNetV2 embeddings provide deep visual patterns that complement engineered features.

## Data Management

### Preventing Leakage

The data manifest prevents common issues:

1. **Near-Duplicate Detection**: Perceptual hashing finds similar scans
2. **Grouped CV**: Same card (base_id) always in same fold
3. **Front/Back Pairing**: Tracks paired images for future penalty system

```bash
# Check your data quality
python scripts/data_management/create_data_manifest.py --data-dir data/training
```

### Confusion Analysis

After training, analyze errors for targeted improvement:

```bash
# Generate predictions first, then analyze
python scripts/analysis/confusion_analysis.py \
    --predictions results/predictions.csv \
    --output analysis/
```

Outputs:
- `confusion_matrix.png` - Visual heatmap
- `per_grade_accuracy.csv` - Breakdown by grade
- `confusion_report.md` - Recommendations

## Back-of-Card Setup

The model supports paired front/back card images. To add back-of-card data:

```bash
# Folder structure is ready:
data/
â”œâ”€â”€ training_front/    # Front images (existing)
â”‚   â”œâ”€â”€ PSA_1/
â”‚   â”œâ”€â”€ PSA_2/
â”‚   ...
â””â”€â”€ training_back/     # Back images (add your images here)
    â”œâ”€â”€ PSA_1/
    â”œâ”€â”€ PSA_2/
    ...

# After adding back images, extract features:
python scripts/feature_extraction/extract_advanced_features.py \
    --data-dir data/training_back \
    --output-base models/advanced_features_back

# The training script will automatically detect and use back features
Rscript training/train_full_pipeline.R
```

## Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ training_front/        # Front card images (PSA_1 through PSA_10)
â”‚   â”œâ”€â”€ training_back/         # Back card images (same structure)
â”‚   â”œâ”€â”€ data_manifest.csv      # Full manifest with duplicate flags
â”‚   â””â”€â”€ data_manifest_clean.csv # Deduplicated images
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ensemble_model.rds     # 5-model ensemble + specialists
â”‚   â”œâ”€â”€ tiered_model.rds       # Single tiered model
â”‚   â”œâ”€â”€ advanced_features.csv  # Extracted features
â”‚   â””â”€â”€ cnn_features_mobilenetv2.csv
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ feature_extraction/
â”‚   â”‚   â”œâ”€â”€ extract_advanced_features.py   # Main extractor (v4)
â”‚   â”‚   â”œâ”€â”€ extract_features_tta.py        # Test-time augmentation
â”‚   â”‚   â””â”€â”€ extract_cnn_features_*.py      # CNN features
â”‚   â”œâ”€â”€ data_management/
â”‚   â”‚   â””â”€â”€ create_data_manifest.py        # Deduplication + CV splits
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ confusion_analysis.py          # Error analysis
â”‚   â””â”€â”€ llm_integration/
â”‚       â””â”€â”€ llm_grading_assistant.py       # LLM visual auditor
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_ensemble_model.R   # â˜… Best accuracy (60%+ target)
â”‚   â””â”€â”€ train_tiered_model.R     # Single model (faster)
â”‚
â”œâ”€â”€ Prediction_New/
â”‚   â”œâ”€â”€ predict_ensemble.R       # â˜… Ensemble prediction
â”‚   â””â”€â”€ predict_new.R            # Single model prediction
â”‚
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluate_tiered_cv.R     # Cross-validation
â”‚
â”œâ”€â”€ ios_app/                     # iOS app for mobile grading
â”‚   â”œâ”€â”€ backend/api_server.py
â”‚   â””â”€â”€ PSAGrader/*.swift
â”‚
â””â”€â”€ old_versions/                # Archived previous versions
```

## Running Evaluation

To get actual performance numbers:

```bash
# Train ensemble and see CV results
Rscript training/train_ensemble_model.R

# Results will show:
# - 5-fold cross-validation metrics
# - Per-grade exact match accuracy
# - Saved to models/ensemble_cv_results.csv
```

## Web App (Mobile-Friendly)

Access the grader from any device with a browser:

```bash
# Install dependencies
cd webapp
pip install -r requirements.txt

# Run the server
python app.py

# Access at http://localhost:5000
# Or from phone: http://<your-ip>:5000
```

Features:
- Camera capture or photo upload
- Real-time grade predictions
- Confidence scores and probability breakdown
- Works on iOS, Android, and desktop

## iOS App (Native)

Native iOS app for offline predictions:

```bash
# Start backend
cd ios_app/backend
pip install -r requirements.txt
python api_server.py

# Then run iOS app in Xcode
```

See [ios_app/README.md](ios_app/README.md) for setup details.

## Improvement Roadmap

### Implemented âœ…

- [x] Adaptive ROI patching (contour-based corners)
- [x] Art-Box mathematical centering
- [x] Binary Triage architecture
- [x] 5-model ensemble with diverse configs
- [x] Confusion-pair specialists
- [x] Ordinal-aware training
- [x] Temperature calibration
- [x] Test-time augmentation
- [x] Data manifest with deduplication
- [x] Grouped CV (leakage prevention)
- [x] LLM visual auditor integration
- [x] iOS mobile app
- [x] **Mobile web app** (Flask-based, works on any device)
- [x] **CNN Feature Fusion** (MobileNetV2 1,280 dims + engineered features)
- [x] **Back-of-card folder structure** (ready for paired images)
- [x] **Card type tagging** (sports, tcg, unknown in manifest)
- [x] **Cost-sensitive learning** (upweight hard classes)
- [x] **SMOTE oversampling** for PSA 2, 5, 8
- [x] **Uncertainty sampling** for active learning
- [x] **Confusion analysis** with recommendations

### High Priority (Next Steps) ðŸ“‹

- [ ] **Balance hard class weights**: Current weights cause PSA 8 over-prediction
- [ ] **Collect back-of-card images**: Place in `data/training_back/PSA_X/`
- [ ] **Card-type specialists**: Separate models for sports vs TCG
- [ ] **Review uncertain samples**: Use `scripts/analysis/uncertainty_sampling.py`

### Medium Priority ðŸ“‹

- [ ] Core ML model (offline iOS predictions)
- [ ] Gradient-based saliency maps (explainability)
- [ ] Fine-tuned CNN backbone on grading task

## Requirements

- **Python**: 3.8+
- **R**: 4.0+
- **TensorFlow**: 2.x

```bash
# Python dependencies
pip install -r requirements.txt

# R packages
install.packages(c("ranger", "randomForest"))
```

## License

MIT License
